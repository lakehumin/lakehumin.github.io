{"meta":{"title":"Lake's Blog","subtitle":"谦虚 务实 keep moving.","description":null,"author":"Lake","url":"http://lakehumin.github.io"},"pages":[],"posts":[{"title":"Raft学习笔记","slug":"raft","date":"2018-04-05T10:18:17.000Z","updated":"2018-04-05T10:30:46.241Z","comments":true,"path":"2018/04/05/raft/","link":"","permalink":"http://lakehumin.github.io/2018/04/05/raft/","excerpt":"","text":"一些概念 broadcastTime&lt;&lt;electionTimeout&lt;&lt;MTBF broadcastTime。leader发送心跳的时间间隔 electionTimeout。选举超时时长（值随机），若这段时间内没有leader心跳触发选举。 MTBF。服务器发生故障的时间间隔。 MTBF一般为几个月以上。electionTimeout为机器故障时的不可用时长一般为10ms-500ms。broadcastTime应该比electionTimeout小一个数量级，为0.5ms-20ms。 server有三种状态follower、candidate、leader。系统初始为follower状态，超过electionTimeout开始选举。没选出结果超出electionTimeout，继续开始下一轮选举。 三种角色分工 leader：负责日志的同步管理，处理来自客户端的请求，与follower保持这heartBeat的联系 follower：刚启动时所有节点为follower状态，响应leader的日志同步请求，响应candidate的请求，把请求到follower的事务转发给leader candidate：负责选举投票，Raft刚启动时由一个节点从follower转为candidate发起选举，选举出leader后从candidate转为leader状态 服务器状态 在所有服务器上持久存在的：（在响应远程过程调用 RPC 之前稳定存储的） | 名称 | 描述 | | :———: |:——————————————————-:| | currentTerm | 服务器最后知道的任期号（从0开始递增） | | votedFor | 在当前任期内收到选票的候选人 id（如果没有就为 null） | | log[] | 日志条目；每个条目包含状态机的要执行命令和从领导人处收到时的任期号 | 在所有服务器上不稳定存在的： | 名称 | 描述 | | :———: |:——————————————————-:| | commitIndex | 已知的被提交的最大日志条目的索引值（从0开始递增） | | lastApplied | 被状态机执行的最大日志条目的索引值（从0开始递增） | 在领导人服务器上不稳定存在的：（在选举之后初始化的） | 名称 | 描述 | | :———: |:——————————————————-:| | nextIndex[] | 对于每一个服务器，记录需要发给它的下一个日志条目的索引（初始化为领导人上一条日志的索引值+1）| | matchIndex[]| 对于每一个服务器，记录已经复制到该服务器的日志的最高索引值（从0开始递增） | RequestVote RPC数据格式 | 参数 | 描述 | | :———-: |:————————:| | term | 候选人的任期号 | | candidateId | 请求投票的候选人 id | | lastLogIndex | 候选人最新日志条目的索引值 | | lastLogTerm | 候选人最新日志条目对应的任期号 | | 返回值 | 描述 | | :———: |:————————–:| | term | 目前的任期号，用于候选人更新自己 | | voteGranted | 如果候选人收到选票为 true | AppendEntries RPC数据格式 | 参数 | 描述 | | :———-: |:————————————:| | term | leader的任期号 | | leaderId | leader的 id，为了其他服务器能重定向到leader | | prevLogIndex | 最新日志之前的日志的索引值 | | prevLogTerm | 最新日志之前的日志的领导人任期号 | | entries[] | 将要存储的日志条目（表示 heartbeat 时为空，有时会为了效率发送超过一条）| | leaderCommit | 领导人提交的日志条目索引值 | | 返回值 | 描述 | | :—–: |:————————————————————-:| | term | 当前的任期号，用于领导人更新自己的任期号 | | success | 如果其它服务器包含能够匹配上 prevLogIndex 和 prevLogTerm 的日志时为真| 一些疑惑 leader发送心跳后没有收到大多数（大多数指过半，下同）的回复会进入重新选举的状态吗 不会，也没必要。因为这样的leader由于没有大多数follower不会成功响应。另一分区则会进行选举选出term更高的leader。 客户端请求了follower之后如何定位到leader 每次AppendEntries RPC时会带上leaderId，因此follower接到客户端的请求后就能将请求转到leader了。 为什么follower收到candidate的RPC请求后为什么也会重置定时器继续follower的状态 为了减少leader的竞争，尽快选出leader follower的votedFor会不会因为新leader被其他大多数选出来了，而跟着设置为这个leader 不会，设置为任何值都没意义。新leader已经选出，再不会有第二个能获取过半投票。所以可能出现leader选出后，他投票给另一个candidate。 若是某个follower故障导致进入选举会引起集群选举吗 会的，因为此时的term++后比任何服务器都新，会造成所以其他收到RequestVote RPC的服务器更新term变成follower，重新选举。 如何确保快速选出leader 进入选举后很有可能出现选票瓜分的情况，没有一个candidate获得超过半数。发生electionTimeout后重新选举，由于electionTimeout随机，所以必有某服务器先进入选举，有更大可能成为leader，从而能很快的结束选举，选出leader。 candidate收到AppendEntries RPC后，若对方term与自己相等为什么也会变为follower 此时自己没有对方更新的数据，且对方已经被大多数承认为leader，为了快速选出leader没必要继续选举。 如何保证同任期同index的日志内容一样 每台机器都会保存某一任期的投票情况，且一旦投票就不会发生改变。选leader的时候，是收集指定任期的选票情况，过半数才能选为leader。这就保证了具体某一任期的leader独一无二。不会出现两个leader任期相同的情况。然后日志index又是leader给的，所以同任期同index的日志必定是一样的。 是否存在不同任期的日志同index。若存在，那解决日志冲突时会不会出现日志index不连续的情况 存在的。每个日志的追加leader都会按日志index递增，但leader挂了后，会选出新的leader，此时新leader可能没同步到上一个leader的日志，于是就可能出现同index不同任期的日志。但不管怎样对每一个leader来说他们都维护了index的递增，所以最好无论是谁的日志覆盖了谁，最好的index应该都是连续递增的。 为何同任期同index的日志，他们之前的日志也一定相同因为日志append的时候会判断之前的任期和index，只有相同才能append成功，再加上同任期同index日志内容相同的结论。类似数据归纳法，逐个类推，之前所有日志全部相同。 Raft从来不会通过计算复制的数目来提交之前任期的日志条目只有领导人当前任期的日志条目才能通过计算数目来进行提交。一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配原则，之前的日志条目也都会被间接的提交。原因考虑下面的情况：a阶段s1为leader，任期为2。b阶段s5变为leader，任期3。c阶段leader又变成了s1，此时term2index2的日志复制给了大多数，但该日志并不能变成已提交状态。因为此时s1的任期为4，这是在复制以前任期的日志。由于可能出现d阶段s5重新变为leader把term2index2的日志覆盖的情况，所以只能等到e阶段s1将term4index3的日志（属于当前任期的日志）复制给了大多数后，确定term4index3为已提交状态，同时间接将term2index2日志设为已提交。 为何只要leader的AppendEntries RPC收到大多数回复就可以认为该日志为已提交因为若此时leader挂掉，那么由于大多数都有这条最新的日志，选出来的leader必定也有。那么新leader给其他follower同步日志的时候一定会带上这条日志，若新leader有新的日志提交，那么这条日志必定间接提交。若没有新提交那么，该leader再挂，再次选出来的leader也一定包含这条日志（因为一定是因为有最新的日志才会成为新leader，而新的日志必定是上一个leader加上的，考虑prevLogIndex，所以新leader也会带着那条日志），那么问题又回来了。若最初始leader没挂，而是新加了几条日志再挂，新加的日志若成功必定含有该日志，问题回到上面。若不成功（准确说是不确定），则依然是上面的两个问题之一。 若leader的AppendEntries RPC没收到大多数回复该怎么返回若是没有大多数，则可能换leader后，被不带有该日志的leader把其截掉。也可能被带有该日志的leader复制给所有机器。所以都有可能，不确定，返回给客户端不确定的答案，如超时，让他重试。 客户端发起重试的时候怎么确保已经执行过的操作不被重复执行当客户端没收到leader的回复时，可能是leader不确定答案，可能是leader挂了，也可能是leader回复网络丢包等等。此时客户端对同一log发起重试，若之前已经执行过那么这次不应该让leader再次执行。怎么判断这是同一次操作呢？解决办法是，客户端对每条指令都会有一个唯一的序列号。 新leader选出来的时候它是不知道以往日志的提交情况的，往往需要在自己任期提交一次才能确定之前的所有日志为已提交，怎么优化这点之前的leader可能已经设置某log为已提交，但是新leader可能还没有收到commitIndex的更新。那么之后为了确认之前的日志的提交情况，它必须在自己任期成功提交一次。当然你不能等客户端在你任期发起请求，然后你才有机会提交一次。所以最后解决办法是，选为leader的初始发送一个带有空操作log的AppendEntries RPC，一旦成功便可以确认之前所有的提交。 一些流程选举过程 转变为candidate开始选举 candidate的currentTerm++ 给自己投票 重置选举计时器 向其他服务器发送RequestVote RPC 如果收到了来自大多数服务器的投票，则成为leader，并立即发送AppendEntries RPC，以保持leader正常运转。 如果收到了来自其他leader的AppendEntries RPC（heartbeat），则看term是否大于等于currentTerm。是则转换状态为追随者，否则拒绝该请求。 如果选举超时，开始新一轮的选举 log复制过程 客户端请求leader,leader将该请求追加到本地log 向follower发起AppendEntries RPC 当大多数follower回复成功后，设置log为已提交，回复客户端并apply到状态机（操作顺序无所谓，只要大多数回复，后面都是成立的）。 一些规则 所以服务器遵守的规则 如果commitIndex &gt; lastApplied，lastApplied自增，将log[lastApplied]应用到状态机 如果RPC的请求或者响应中包含一个term T大于currentTerm，则currentTerm赋值为T，并切换状态为follower 一个term只能投票给一个服务器 follower遵守的规则 响应来自候选人和领导人的 RPC 如果在超过选取领导人时间之前没有收到来自当前领导人的AppendEntries RPC或者没有收到候选人的投票请求，则自己转换状态为候选人。反之收到了，则重置定时器。 收到RequestVote RPC后 若term&lt;currentTerm，返回false 若term&gt;=currentTerm（都变为candidate的时候可能出现=），则看votedFor是否为null，不是则返回当前投票votedFor是否等于请求的候选人Id。是则比较谁的log更新，即比较lastLogTerm和lastLogIndex。比自己新或是一样新则返回true，并设置votedFor。 收到AppendEntries RPC后 若term&lt;currentTerm，返回false 若prevLogIndex和prevLogTerm能够匹配到自己的log[]中的某条log，则将entries[]应用到prevLogIndex和prevLogTerm后面的日志。否则不能匹配则返回false。 如果leaderCommit &gt; commitIndex，并且此次RPC将要返回true则设置commitIndex= leaderCommit。（你要保证应用到状态机的log和leader一样才行） 经过一系列的AppendEntries RPC后，日志最终会和leader同步 leader遵守的规则 成为leader后，向其他所有服务器发送带空操作log的AppendEntries RPC，在空闲时间重复发送以防止选举超时。 如果收到来自客户端的请求，向本地日志增加条目，并试图复制给其他机器，在收到大多数机器回复后响应客户端成功并设置该日志为已提交，更新commitIndex。 如果follower崩溃了或者运行缓慢或者是网络丢包了，leader会无限的重试AppendEntries RPC（甚至在它向客户端响应之后）直到所有的follower最终存储了所有的日志条目。 每次给follower AppendEntries RPC时会把nextIndex后的所有日志发出去，若follower匹配prevLogIndex和prevLogTerm后返回成功，则更新对应follower的nextIndex和matchIndex。若返回false，则nextIndex减1，下次AppendEntries RPC时重新发送。 参考链接raft英文原版文献raft中文raft小动画","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://lakehumin.github.io/categories/学习笔记/"}],"tags":[{"name":"一致性","slug":"一致性","permalink":"http://lakehumin.github.io/tags/一致性/"},{"name":"raft","slug":"raft","permalink":"http://lakehumin.github.io/tags/raft/"}]},{"title":"TCP相关思考","slug":"TCP","date":"2018-02-25T02:07:12.000Z","updated":"2018-02-25T02:35:58.147Z","comments":true,"path":"2018/02/25/TCP/","link":"","permalink":"http://lakehumin.github.io/2018/02/25/TCP/","excerpt":"","text":"TCP三次握手TCP之所以需要三次握手，问题的本质是一个通信问题。即在信道不可靠的情况下，如何使通信双方就某一问题达成一致。这就需要通信的双方通过某种方式来保证信道在一定程度上可靠。因此，要让通信的双方都能确认自己的信息能传达到对方，同时能够收到对方的信息。如此，信息一去一来，对任意一方来说都需要两次握手才能让他自己确认，自己的信息能被对方接收同时自己能正确接收对方的信息。结论，三次通信是理论上的最小值。通信双方经过三次握手达成建立连接的共识后，自然而然解决掉了诸多通信的异常问题。因此用解决“为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误”之类的说法说明三次握手的作用不够准确。三次握手的实质就是通信双方基于不那么可靠的信道建立可靠通信连接的一种方式。 TCP四次挥手TCP通信的双方断开连接需要双方确认没有数据发送并请求断开，在已经建立连接的情况下理论上需要双方各两次通信。一次请求，一次ACK，可以确认一方没有数据发送并断开连接。但最后一次ACK怎么确保一定送达，这里通过time_wait状态加上重试机制保证。当一方发出最后一个ACK后等待2MSL时间，期间若对方没有收到ACK必会重试，2MSL内必会收到重试FIN报文。因此，保证了2MSL时间后对方收到ACK，可以正常断开TCP连接。个人觉得2MSL不够准确，应该取MSL+超时重传累积时间的总和。猜测取2MSL是因为，最差可能是1MSL后重试，并且重试一次足矣，网络也没那么差 TCP心跳的意义由于TCP连接是虚拟的连接，当一方断网或是断电等异常断开后，另一方是无法知道TCP连接已经断开的。为了减少这种不必要的连接浪费资源，需要心跳及时发现连接断开这种情况。心跳有TCP自带的keep_alive和应用层心跳。重点：运营商也会断掉长时间没有数据的连接","categories":[{"name":"思考总结","slug":"思考总结","permalink":"http://lakehumin.github.io/categories/思考总结/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://lakehumin.github.io/tags/网络/"}]},{"title":"ZooKeeper学习笔记","slug":"ZooKeeperNote","date":"2018-02-25T02:07:12.000Z","updated":"2018-02-25T02:35:58.151Z","comments":true,"path":"2018/02/25/ZooKeeperNote/","link":"","permalink":"http://lakehumin.github.io/2018/02/25/ZooKeeperNote/","excerpt":"","text":"FastLeaderElection选举算法核心思想通过不断更新自己的选举结果，广播消息，让其他人知道自己的推荐leader，来让所有人尽快达成一致 一些概念 electionEpoch 它是选举算法FastLeaderElection的一个属性（也被叫做logicalclock），在zookeeper的server启动的时候就会创建选举算法，该值初始是0，之后该server每执行一次选举，electionEpoch 就会自增，同时在选举的时候，一旦别人的投票中的electionEpoch 比自己的大，也会更新自己的electionEpoch来和别人保持一致 proposedLeader 推荐的leader id。为被推荐leader的myid的值 proposedZxid 推荐leader的最大事务zxid，由本地文件恢复得到，为被推荐leader机器的lastProcessedZxid。表示该被推荐的leader所保留的最新的事务，用于选举的比较 proposedEpoch peerEpoch值，由上述的lastProcessedZxid的高32得到 一些理念 若是选出leader，再收到投票消息会直接返回选举结果 判断规则 先比较peerEpoch，再zxid，最后是myid，胜者被推荐为leader 系统稳定运行的关键 有一个Leader，并且多数Follower认可这个Leader 大多数认定即可 一些疑问 为什么收到消息的electionEpoch大于当前logicallock后，会更新logicallock为收到的electionEpoch，并清空票箱recvset 是为了保证这是最新的同一次选举 为什么收到的logicalclock比自己小时不予理睬 此算法的核心思想是接收消息，更新自己，再通知大家，直到选出leader。比自己小时不用更新自己，没必要回复，减少不必要的信息传输。后面自然会有更新消息通知到他，让其更新logicalclock。 当统计选票确定leader后，如何确保其他大多数机器也认为该leader合法 由于目的是实现系统稳定运行，选出leader。不管过程怎样最后是系统稳定运行的状态即可。当统计选票确定leader后会等待一段时间，看是否有更优的提议，没有就确认当前推荐leader为正式leader，确定对应状态是leader还是follower。其实这一步也只能基本保证该leader合法。不过没关系，由于leader会不断检测是否依然有多个follower认定自己是leader，follower也会根据leader是否有不断给自己心跳来确定leader是否有效。因此，若出现最初统计的leader不合法后，会再次进行选举，最后一定会形成系统稳定运行的状态。 选举流程 发起选举logicalclock++，推荐自己为leader，设置当前投票为本机myid, lastProcessedZxid, peerEpoch。并通知所有服务器。 只要当前服务器状态为LOOKING，进入循环，不断地读取其它Server发来的通知、进行比较、更新自己的投票、发送自己的投票、统计投票结果，直到leader选出或出错退出。收到通知后，根据对方状态进行处理 LOOKING状态 如果发送过来的逻辑时钟大于目前的逻辑时钟，那么说明这是更新的一次选举投票，此时更新本机的逻辑时钟logicalclock，清空投票箱（因为已经过期没有用了），调用totalOrderPredicate函数判断对方的投票是否优于当前的投票（判断规则上面提过了），是的话用对方推荐的leader更新下一次的投票，否则使用初始的投票（投自己），最后都将调用sendNotifications() 通知所有服务器我的选择，并将投票信息放入投票箱recvset。 如果对方处于上轮投票，即electionEpoch比我小，则不予理睬 如果对方也处于本轮投票，调用totalOrderPredicate函数判断对方的投票是否优于当前的投票，是的话更新当前的投票并新生成notification消息放入发送队列，否则使用初始的投票（投自己）不发送通知。投票信息放入投票箱。 统计投票结果，判断所推荐的leader是否得到集群多数人的同意（根据计票器的实现不同，可以是单纯看数量是否超过n/2，也可以是按权重来判断，我们这里假设单纯看数量），如果得到多数人同意，那么还需等待一段时间，看是否有比当前更优的提议，如果没有，则认为投票结束。根据投票结果修改自己的状态。以上任何一条不满足，则继续循环。 OBSERVING状态 不做任何事 FOLLOWING或LEADING状态 如果选举周期相同（选票是同一轮选举产生），将该数据保存到投票箱，根据当前投票箱的投票判断对方推荐的leader是否得到多数人的同意，如果是则设置状态退出选举过程，否则执行下面第2步。 这是一条与当前逻辑时钟不符合的消息，或者对方推荐的leader没有得到多数人的同意（有可能是收集到的投票数不够），那么说明可能在另一个选举过程中已经有了选举结果，于是将该选举结果加入到outofelection集合中，再根据outofelection来判断是否可以结束选举，如果可以也是保存逻辑时钟，设置状态，退出选举过程。否则继续循环。outofelection用于保存那些状态为FOLLOWING或者LEADING的ZooKeeper节点发送的选票，由于对方的状态为FOLLOWING或者LEADING，所以它们当前不参与选举过程（可能人家已经选完了），因此称为“out of election”。 参考链接ZooKeeper的一致性算法赏析Zookeeper架构及FastLeaderElection机制Zookeeper的FastLeaderElection算法分析 zookeeper一致性保证 所有机器按照事务zxid顺序执行便能实现最终一致性 先发起proposal，获得过半ACK后发起commit。两段提交保证响应成功即事务操作成功。集群最终将全部实现该操作。 参考ZooKeeper应用场景及解析","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://lakehumin.github.io/categories/学习笔记/"}],"tags":[{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"http://lakehumin.github.io/tags/ZooKeeper/"}]},{"title":"paxos算法学习总结","slug":"paxos","date":"2018-02-25T02:07:12.000Z","updated":"2018-04-05T10:30:46.237Z","comments":true,"path":"2018/02/25/paxos/","link":"","permalink":"http://lakehumin.github.io/2018/02/25/paxos/","excerpt":"","text":"核心思想分布式系统架构下如何让整体尽快达成一致观点，也就是多个不同观点收敛到一个观点的过程。 难点 可能会发生少数节点故障，但绝不是大面积故障，不然系统也没法正常工作。 由于存在单点故障，因此不可能将观点由某一台机器的统一。共享内存达到一致性的方案不可取。因此，只能是点对点通信。 一些概念 算法中有三个角色Proposor，Acceptor，Learner 算法有两个阶段，一是预提案，二是正式提案。正式提案的内容也就是观点，预提案不带观点 一些疑惑 为什么要有两段提交 一方面，第一次预提交后可能被告知已经有观点了，此时他不应该提出自己的观点，而应该尽快收敛，支持最新的观点。另一方面，进行预加锁。 怎么保证Proposal编号唯一 假设有K台Server运行paxos算法，那么他们初始编号为0…k-1。以后编号每次增加k，从而保证全局唯一递增。 Acceptor为什么只接受最大编号的提案（包括预提案和最终提案） 要收敛就得定个收敛的方向。编号越大，提案越新，方便所有观点向一个方向（编号最大）收敛。 预提案为什么要获取大多数接受后才开始正式提案 尽可能保证正式提案能够通过，没有过半的预提案没有意义。毕竟只要多数（过半）认为提案通过，那么该观点就达成一致。 正式提案时为什么提案内容也就是观点要选择预提案回复中编号最大的观点 为了尽快形成多数派，达成观点一致 正式提案被半数以上Acceptor接受后，就可以确定最终被接受的提案就是该观点 如果有后来编号更大的提案N来更新当前多数派观点，那么该提案在预提案中获得多数派认可。由于已经有多数派接受了当前观点，那么提案N的预提案对于每一个Acceptor来说都是晚于当前观点的正式提案的，不然当前观点的正式提案不会接受。那么提案N的预提案必会收到当前观点的Proposal回复，他的正式提案也将会是响应当前观点。这也是为什么要有两段提交的原因。 Acceptor是否会因为编号最新的正式提案修改之前接受的观点 会，为了更快的收敛观点。 如何确定能最终收敛 根据Fischer-Lynch-Paterson结论，在一个多进程异步系统中，只要有一个进程不可靠，那么就不存在一个协议，此协议能保证有限时间内使所有进程达成一致。因此paxos算法存在活锁问题，即有可能一直没法收敛。比如，预提案一直没法得到过半Acceptor接受，总是会有因为失败重新生成更大编号的Proposor来阻止通过预提案。同样，即使通过了预提案，后面也会有其他更大编号的预提案发起导致无法通过正式提案。但这种事发生的可能性比较小。特别是第二段提交降低了这种概率（见疑惑1）。理论上虽然可能永远不收敛，但概率很小，实际上好用就行。毕竟是做工程嘛！ 如何确保收到预提案Acceptor的回复后，你能拿到编号最大的被接受的正式提案 无法保证也无需保证，目的是尽快收敛，收敛到任一观点都行 一些约束 Acceptor总是会接受编号最大的预提案及正式提案 Acceptor不接受提案时也应该回复一个拒绝消息（或者超时也是一种拒绝） 工作流程Proposor工作流程 生成一个编号，向所有Acceptor发起预提案，此次不带提案内容 若没有获得过半Acceptor通过，则重新生成一个更大的编号并发起预提案 若通过，先检查返回结果里Acceptor接受的正式提案 若存在已被接受的正式提案，则第二阶段的正式提案内容为回复中编号最大的已被接受的提案内容 若不存在，第二阶段提案内容为自己选择 进行第二阶段提交，向所有Acceptor发起正式提案 若过半Acceptor接受则流程结束，提案内容被正式确定 若没过半的Acceptor接受则从2开始重新执行流程 Acceptor工作流程 若是收到预提案请求，根据之前的承诺，不接受小于编号XXX的请求（第一次没有承诺，均接受）来进行判断 此次编号小于XXX，则回复拒绝 此次编号大于XXX，则回复接受 若之前有接受过正式提案，还会回复正式提案的内容及编号 若没有则回复null 若是收到正式提案请求，也会根据之前的承诺，不接受小于XXX编号的请求，进行判断 此次编号小于XXX，则回复拒绝 此次编号大于等于XXX，则回复接受 最后的结论当某正式提案被过半Acceptor接受后，整个系统最终会达成一致，共同赞成该提案的观点 提下Multi-Paxos实际上在Basic-Paxos中如果一个Proposer A提交的协议每次都被其他Acceptor正常接受（即没有其他的人做Proposer），那么实际上Basic-Paxos中此Proposer A在下一轮的投票中也完全可以不需要发起Prepare阶段，直接进入Accept，直到有人也开始做Proposer打破了A的“统治”，A才需要再次发起Prepare提高自己的ProposalId，由此为了优化投票过程，我们只需要保证A的统治尽可能不被打破，很简单那就不让其他的节点随意具有发起投票的权力就可以了，只有一个节点具有，所以Leader的概念就有了，而非Multi-Paxos必须有Leader！ 具体做法是，收到来自其他节点的Accept，则进行一段时间的拒绝提交请求。这样就不会提高ProposalId，达到一种各个节点都想着不要去打破这种连续Accept的状态。当有一个节点在连续的Accept，那么其他节点必然持续不断的拒绝请求。这个Leader就这样无形的被产生出来了，我们压根没有刻意去“选举”，它就是来自于Multi-Paxos算法。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://lakehumin.github.io/categories/学习笔记/"}],"tags":[{"name":"paxos","slug":"paxos","permalink":"http://lakehumin.github.io/tags/paxos/"},{"name":"一致性","slug":"一致性","permalink":"http://lakehumin.github.io/tags/一致性/"}]},{"title":"浏览器访问google.com后发生了什么？","slug":"curlgooglecom","date":"2017-07-29T12:51:12.000Z","updated":"2018-01-06T02:50:11.332Z","comments":true,"path":"2017/07/29/curlgooglecom/","link":"","permalink":"http://lakehumin.github.io/2017/07/29/curlgooglecom/","excerpt":"","text":"浏览器输入google.com后发生的事“g”键按下接下来的内容介绍了物理键盘和系统中断的工作原理，但是有一部分内容却没有涉及。当你按下g键，浏览器接收到这个消息之后，会触发自动完成机制。浏览器根据自己的算法，以及你是否处于隐私浏览模式，会在浏览器的地址框下方给出输入建议。大部分算法会优先考虑根据你的搜索历史和书签等内容给出建议。你打算输入google.com，因此给出的建议并不匹配。但是输入过程中仍然有大量的代码在后台运行，你的每一次按键都会使得给出的建议更加准确。甚至有可能在你输入之前，浏览器就将google.com 建议给你。 回车键按下为了从零开始，我们选择键盘上的回车键被按到最低处作为起点。在这个时刻，一个专用于回车键的电流回路被直接地或者通过电容器间接地闭合了，使得少量的电流进入了键盘的逻辑电路系统。这个系统会扫描每个键的状态，对于按键开关的电位弹跳变化进行噪音消除(debounce)，并将其转化为键盘码值。在这里，回车的码值是13。键盘控制器在得到码值之后，将其编码，用于之后的传输。现在这个传输过程几乎都是通过通用串行总线(USB)或者蓝牙(Bluetooth)来进行的，以前是通过PS/2或者ADB连接进行。 USB键盘： 键盘的USB元件通过计算机上的USB接口与USB控制器相连接，USB接口中的第一号针为它提供了5V的电压 键码值存储在键盘内部电路一个叫做endpoint的寄存器内 USB控制器大概每隔10ms便查询一次endpoint以得到存储的键码值数据，这个最短时间间隔由键盘提供 键值码值通过USB串行接口引擎被转换成一个或者多个遵循低层USB协议的USB数据包 这些数据包通过D+针或者D-针(中间的两个针)，以最高1.5Mb/s的速度从键盘传输至计算机。速度限制是因为人机交互设备总是被声明成低速设备（USB 2.0 compliance） 这个串行信号在计算机的USB控制器处被解码，然后被人机交互设备通用键盘驱动进行进一步解释。之后按键的码值被传输到操作系统的硬件抽象层 虚拟键盘（触屏设备）： 在现代电容屏上，当用户把手指放在屏幕上时，一小部分电流从传导层的静电域经过手指传导，形成了一个回路，使得屏幕上触控的那一点电压下降，屏幕控制器产生一个中断，报告这次点击的坐标 然后移动操作系统通知当前活跃的应用，有一个点击事件发生在它的某个GUI部件上了，现在这个部件是虚拟键盘的按钮 虚拟键盘引发一个软中断，返回给OS一个按键按下消息 这个消息又返回来向当前活跃的应用通知一个按键按下事件 产生中断[非USB键盘]键盘在它的中断请求线(IRQ)上发送信号，信号会被中断控制器映射到一个中断向量，实际上就是一个整型数 。CPU使用中断描述符表(IDT)把中断向量映射到对应函数，这些函数被称为中断处理器，它们由操作系统内核提供。当一个中断到达时，CPU根据IDT和中断向量索引到对应的中断处理器，然后操作系统内核出场了。 (Windows)一个 WM_KEYDOWN 消息被发往应用程序HID把键盘按下的事件传送给 KBDHID.sys 驱动，把HID的信号转换成一个扫描码(Scancode)，这里回车的扫描码是 VK_RETURN(0x0d)。 KBDHID.sys 驱动和 KBDCLASS.sys (键盘类驱动,keyboard class driver)进行交互，这个驱动负责安全地处理所有键盘和小键盘的输入事件。之后它又去调用 Win32K.sys ，在这之前有可能把消息传递给安装的第三方键盘过滤器。这些都是发生在内核模式。 Win32K.sys 通过 GetForegroundWindow() API函数找到当前哪个窗口是活跃的。这个API函数提供了当前浏览器的地址栏的句柄。Windows系统的message pump机制调用 SendMessage(hWnd, WM_KEYDOWN, VK_RETURN, lParam) 函数， lParam 是一个用来指示这个按键的更多信息的掩码，这些信息包括按键重复次数（这里是0），实际扫描码（可能依赖于OEM厂商，不过通常不会是 VK_RETURN ），功能键（alt, shift, ctrl）是否被按下（在这里没有），以及一些其他状态。 Windows的 SendMessage API直接将消息添加到特定窗口句柄 hWnd 的消息队列中，之后赋给 hWnd 的主要消息处理函数 WindowProc 将会被调用，用于处理队列中的消息。 当前活跃的句柄 hWnd 实际上是一个edit control控件，这种情况下，WindowProc 有一个用于处理 WM_KEYDOWN 消息的处理器，这段代码会查看 SendMessage 传入的第三个参数 wParam ，因为这个参数是 VK_RETURN ，于是它知道用户按下了回车键。 (Mac OS X)一个 KeyDown NSEvent被发往应用程序中断信号引发了I/O Kit Kext键盘驱动的中断处理事件，驱动把信号翻译成键码值，然后传给OS X的 WindowServer 进程。然后， WindowServer 将这个事件通过Mach端口分发给合适的（活跃的，或者正在监听的）应用程序，这个信号会被放到应用程序的消息队列里。队列中的消息可以被拥有足够高权限的线程使用 mach_ipc_dispatch 函数读取到。这个过程通常是由 NSApplication 主事件循环产生并且处理的，通过 NSEventType 为 KeyDown 的 NSEvent 。 (GNU/Linux)Xorg 服务器监听键码值当使用图形化的 X Server 时，X Server 会按照特定的规则把键码值再一次映射，映射成扫描码。当这个映射过程完成之后， X Server 把这个按键字符发送给窗口管理器(DWM，metacity, i3等等)，窗口管理器再把字符发送给当前窗口。当前窗口使用有关图形API把文字打印在输入框内。 输入的是 URL 还是搜索的关键字？当协议或主机名不合法时，浏览器会将地址栏中输入的文字传给默认的搜索引擎。大部分情况下，在把文字传递给搜索引擎的时候，URL会带有特定的一串字符，用来告诉搜索引擎这次搜索来自这个特定浏览器。 解析URL浏览器通过 URL 能够知道下面的信息： Protocol http使用HTTP协议 Resource /请求的资源是主页(index) 转换非 ASCII 的 Unicode 字符 浏览器检查输入是否含有不是 a-z， A-Z，0-9， - 或者 . 的字符 这里主机名是 google.com ，所以没有非ASCII的字符；如果有的话，浏览器会对主机名部分使用 Punycode 编码 检查 HSTS 列表 浏览器检查自带的预加载 HSTS（HTTP严格传输安全）列表，这个列表里包含了那些请求浏览器只使用HTTPS进行连接的网站 如果网站在这个列表里，浏览器会使用 HTTPS 而不是 HTTP 协议，否则，最初的请求会使用HTTP协议发送 注意，一个网站哪怕不在 HSTS 列表里，也可以要求浏览器对自己使用 HSTS 政策进行访问。浏览器向网站发出第一个 HTTP 请求之后，网站会返回浏览器一个响应，请求浏览器只使用 HTTPS 发送请求。然而，就是这第一个 HTTP 请求，却可能会使用户受到 downgrade attack 的威胁，这也是为什么现代浏览器都预置了 HSTS 列表。 DNS 查询 浏览器检查域名是否在缓存当中（要查看 Chrome 当中的缓存， 打开 chrome://net-internals/#dns）。 如果缓存中没有，就去调用 gethostbyname 库函数（操作系统不同函数也不同）进行查询。 gethostbyname 函数在试图进行DNS解析之前首先检查域名是否在本地 Hosts 里，Hosts 的位置 不同的操作系统有所不同 如果 gethostbyname 没有这个域名的缓存记录，也没有在 hosts 里找到，它将会向 DNS 服务器发送一条 DNS 查询请求。DNS 服务器是由网络通信栈提供的，通常是本地路由器或者 ISP 的缓存 DNS 服务器。 查询本地 DNS 服务器 如果 DNS 服务器和我们的主机在同一个子网内，系统会按照下面的 ARP 过程对 DNS 服务器进行 ARP查询 如果 DNS 服务器和我们的主机在不同的子网，系统会按照下面的 ARP 过程对默认网关进行查询 ARP 过程要想发送 ARP（地址解析协议）广播，我们需要有一个目标 IP 地址，同时还需要知道用于发送 ARP 广播的接口的 MAC 地址。 首先查询 ARP 缓存，如果缓存命中，我们返回结果：目标 IP = MAC 如果缓存没有命中： 查看路由表，看看目标 IP 地址是不是在本地路由表中的某个子网内。是的话，使用跟那个子网相连的接口，否则使用与默认网关相连的接口。 查询选择的网络接口的 MAC 地址 我们发送一个二层（ OSI 模型 中的数据链路层）ARP 请求： 123456ARP Request:Sender MAC: interface:mac:address:hereSender IP: interface.ip.goes.hereTarget MAC: FF:FF:FF:FF:FF:FF (Broadcast)Target IP: target.ip.goes.here 根据连接主机和路由器的硬件类型不同，可以分为以下几种情况： 直连： 如果我们和路由器是直接连接的，路由器会返回一个 ARP Reply （见下面）。集线器： 如果我们连接到一个集线器，集线器会把 ARP 请求向所有其它端口广播，如果路由器也连接在其中，它会返回一个 ARP Reply 。 交换机： 如果我们连接到了一个交换机，交换机会检查本地 CAM/MAC 表，看看哪个端口有我们要找的那个 MAC 地址，如果没有找到，交换机会向所有其它端口广播这个 ARP 请求。 如果交换机的 MAC/CAM 表中有对应的条目，交换机会向有我们想要查询的 MAC 地址的那个端口发送 ARP 请求 如果路由器也连接在其中，它会返回一个 ARP Reply 123456ARP Reply:Sender MAC: target:mac:address:hereSender IP: target.ip.goes.hereTarget MAC: interface:mac:address:hereTarget IP: interface.ip.goes.here 现在我们有了 DNS 服务器或者默认网关的 IP 地址，我们可以继续 DNS 请求了： 使用 53 端口向 DNS 服务器发送 UDP 请求包，如果响应包太大，会使用 TCP 协议 如果本地/ISP DNS 服务器没有找到结果，它会发送一个递归查询请求，一层一层向高层 DNS 服务器做查询，直到查询到起始授权机构，如果找到会把结果返回 使用套接字当浏览器得到了目标服务器的 IP 地址，以及 URL 中给出来端口号（http 协议默认端口号是 80， https 默认端口号是 443），它会调用系统库函数 socket ，请求一个 TCP流套接字，对应的参数是 AF_INET/AF_INET6 和 SOCK_STREAM 。 这个请求首先被交给传输层，在传输层请求被封装成 TCP segment。目标端口会被加入头部，源端口会在系统内核的动态端口范围内选取（Linux下是ip_local_port_range) TCP segment 被送往网络层，网络层会在其中再加入一个 IP 头部，里面包含了目标服务器的IP地址以及本机的IP地址，把它封装成一个TCP packet。 这个 TCP packet 接下来会进入链路层，链路层会在封包中加入 frame头 部，里面包含了本地内置网卡的MAC地址以及网关（本地路由器）的 MAC 地址。像前面说的一样，如果内核不知道网关的 MAC 地址，它必须进行 ARP 广播来查询其地址。 到了现在，TCP 封包已经准备好了，可以使用下面的方式进行传输： 以太网 WiFi 蜂窝数据网络 对于大部分家庭网络和小型企业网络来说，封包会从本地计算机出发，经过本地网络，再通过调制解调器把数字信号转换成模拟信号，使其适于在电话线路，有线电视光缆和无线电话线路上传输。在传输线路的另一端，是另外一个调制解调器，它把模拟信号转换回数字信号，交由下一个 网络节点 处理。节点的目标地址和源地址将在后面讨论。 大型企业和比较新的住宅通常使用光纤或直接以太网连接，这种情况下信号一直是数字的，会被直接传到下一个 网络节点 进行处理。 最终封包会到达管理本地子网的路由器。在那里出发，它会继续经过自治区域(autonomous system, 缩写 AS)的边界路由器，其他自治区域，最终到达目标服务器。一路上经过的这些路由器会从IP数据报头部里提取出目标地址，并将封包正确地路由到下一个目的地。IP数据报头部 time to live (TTL) 域的值每经过一个路由器就减1，如果封包的TTL变为0，或者路由器由于网络拥堵等原因封包队列满了，那么这个包会被路由器丢弃。 上面的发送和接受过程在 TCP 连接期间会发生很多次： 客户端选择一个初始序列号(ISN)，将设置了 SYN 位的封包发送给服务器端，表明自己要建立连接并设置了初始序列号 服务器端接收到 SYN 包，如果它可以建立连接： 服务器端选择它自己的初始序列号 服务器端设置 SYN 位，表明自己选择了一个初始序列号 服务器端把 (客户端ISN + 1) 复制到 ACK 域，并且设置 ACK 位，表明自己接收到了客户端的第一个封包 客户端通过发送下面一个封包来确认这次连接： 自己的序列号+1 接收端 ACK+1 设置 ACK 位 数据通过下面的方式传输： 当一方发送了N个 Bytes 的数据之后，将自己的 SEQ 序列号也增加N 另一方确认接收到这个数据包（或者一系列数据包）之后，它发送一个 ACK 包，ACK 的值设置为接收到的数据包的最后一个序列号 关闭连接时： 要关闭连接的一方发送一个 FIN 包 另一方确认这个 FIN 包，并且发送自己的 FIN 包 要关闭的一方使用 ACK 包来确认接收到了 FIN TLS 握手 客户端发送一个 ClientHello 消息到服务器端，消息中同时包含了它的 Transport Layer Security (TLS) 版本，可用的加密算法和压缩算法。 服务器端向客户端返回一个 ServerHello 消息，消息中包含了服务器端的TLS版本，服务器所选择的加密和压缩算法，以及数字证书认证机构（Certificate Authority，缩写 CA）签发的服务器公开证书，证书中包含了公钥。客户端会使用这个公钥加密接下来的握手过程，直到协商生成一个新的对称密钥 客户端根据自己的信任CA列表，验证服务器端的证书是否可信。如果认为可信，客户端会生成一串伪随机数，使用服务器的公钥加密它。这串随机数会被用于生成新的对称密钥 服务器端使用自己的私钥解密上面提到的随机数，然后使用这串随机数生成自己的对称主密钥 客户端发送一个 Finished 消息给服务器端，使用对称密钥加密这次通讯的一个散列值 服务器端生成自己的 hash 值，然后解密客户端发送来的信息，检查这两个值是否对应。如果对应，就向客户端发送一个 Finished 消息，也使用协商好的对称密钥加密 从现在开始，接下来整个 TLS 会话都使用对称秘钥进行加密，传输应用层（HTTP）内容 HTTP 协议如果浏览器是 Google 出品的，它不会使用 HTTP 协议来获取页面信息，而是会与服务器端发送请求，商讨使用 SPDY 协议。 如果浏览器使用 HTTP 协议而不支持 SPDY 协议，它会向服务器发送这样的一个请求: 1234GET / HTTP/1.1Host: google.comConnection: close[其他头部] 其他头部包含了一系列的由冒号分割开的键值对，它们的格式符合HTTP协议标准，它们之间由一个换行符分割开来。（这里我们假设浏览器没有违反HTTP协议标准的bug，同时假设浏览器使用 HTTP/1.1 协议，不然的话头部可能不包含 Host 字段，同时 GET 请求中的版本号会变成 HTTP/1.0 或者 HTTP/0.9 。） HTTP/1.1 定义了关闭连接的选项 close，发送者使用这个选项指示这次连接在响应结束之后会断开。例如： Connection:close 不支持持久连接的 HTTP/1.1 应用必须在每条消息中都包含 close 选项。 在发送完这些请求和头部之后，浏览器发送一个换行符，表示要发送的内容已经结束了。 服务器端返回一个响应码，指示这次请求的状态，响应的形式是这样的: 12200 OK[响应头部] 然后是一个换行，接下来有效载荷(payload)，也就是 www.google.com 的HTML内容。服务器下面可能会关闭连接，如果客户端请求保持连接的话，服务器端会保持连接打开，以供之后的请求重用。 如果浏览器发送的HTTP头部包含了足够多的信息（例如包含了 Etag 头部），以至于服务器可以判断出，浏览器缓存的文件版本自从上次获取之后没有再更改过，服务器可能会返回这样的响应: 12304 Not Modified[响应头部] 这个响应没有有效载荷，浏览器会从自己的缓存中取出想要的内容。 在解析完 HTML 之后，浏览器和客户端会重复上面的过程，直到HTML页面引入的所有资源（图片，CSS，favicon.ico等等）全部都获取完毕，区别只是头部的 GET / HTTP/1.1 会变成 GET /$(相对www.google.com的URL) HTTP/1.1 。 如果HTML引入了 www.google.com 域名之外的资源，浏览器会回到上面解析域名那一步，按照下面的步骤往下一步一步执行，请求中的 Host 头部会变成另外的域名。 HTTP 服务器请求处理HTTPD(HTTP Daemon)在服务器端处理请求/响应。最常见的 HTTPD 有 Linux 上常用的 Apache 和 nginx，以及 Windows 上的 IIS。 HTTPD 接收请求 服务器把请求拆分为以下几个参数： HTTP 请求方法(GET, POST, HEAD, PUT, DELETE, CONNECT, OPTIONS, 或者 TRACE)。直接在地址栏中输入 URL 这种情况下，使用的是 GET 方法 域名：google.com 请求路径/页面：/ (我们没有请求google.com下的指定的页面，因此 / 是默认的路径) 服务器验证其上已经配置了 google.com 的虚拟主机 服务器验证 google.com 接受 GET 方法 服务器验证该用户可以使用 GET 方法(根据 IP 地址，身份信息等) 如果服务器安装了 URL 重写模块（例如 Apache 的 mod_rewrite 和 IIS 的 URL Rewrite），服务器会尝试匹配重写规则，如果匹配上的话，服务器会按照规则重写这个请求 服务器根据请求信息获取相应的响应内容，这种情况下由于访问路径是 / ,会访问首页文件（你可以重写这个规则，但是这个是最常用的）。 服务器会使用指定的处理程序分析处理这个文件，假如 Google 使用 PHP，服务器会使用 PHP 解析 index 文件，并捕获输出，把 PHP 的输出结果返回给请求者 浏览器背后的故事当服务器提供了资源之后（HTML，CSS，JS，图片等），浏览器会执行下面的操作： 解析 —— HTML，CSS，JS 渲染 —— 构建 DOM 树 -&gt; 渲染 -&gt; 布局 -&gt; 绘制 浏览器浏览器的功能是从服务器上取回你想要的资源，然后展示在浏览器窗口当中。资源通常是 HTML 文件，也可能是 PDF，图片，或者其他类型的内容。资源的位置通过用户提供的 URI(Uniform Resource Identifier) 来确定。 浏览器解释和展示 HTML 文件的方法，在 HTML 和 CSS 的标准中有详细介绍。这些标准由 Web 标准组织 W3C(World Wide Web Consortium) 维护。 不同浏览器的用户界面大都十分接近，有很多共同的 UI 元素： 一个地址栏 后退和前进按钮 书签选项 刷新和停止按钮 主页按钮 浏览器高层架构 组成浏览器的组件有： 用户界面 用户界面包含了地址栏，前进后退按钮，书签菜单等等，除了请求页面之外所有你看到的内容都是用户界面的一部分 浏览器引擎 浏览器引擎负责让 UI 和渲染引擎协调工作 渲染引擎 渲染引擎负责展示请求内容。如果请求的内容是 HTML，渲染引擎会解析 HTML 和 CSS，然后将内容展示在屏幕上 网络组件 网络组件负责网络调用，例如 HTTP 请求等，使用一个平台无关接口，下层是针对不同平台的具体实现 UI后端 UI 后端用于绘制基本 UI 组件，例如下拉列表框和窗口。UI 后端暴露一个统一的平台无关的接口，下层使用操作系统的 UI 方法实现 Javascript 引擎 Javascript 引擎用于解析和执行 Javascript 代码 数据存储 数据存储组件是一个持久层。浏览器可能需要在本地存储各种各样的数据，例如 Cookie 等。浏览器也需要支持诸如 localStorage，IndexedDB，WebSQL 和 FileSystem 之类的存储机制 HTML 解析浏览器渲染引擎从网络层取得请求的文档，一般情况下文档会分成8kB大小的分块传输。 HTML 解析器的主要工作是对 HTML 文档进行解析，生成解析树。 解析树是以 DOM 元素以及属性为节点的树。DOM是文档对象模型(Document Object Model)的缩写，它是 HTML 文档的对象表示，同时也是 HTML 元素面向外部(如Javascript)的接口。树的根部是Document对象。整个 DOM 和 HTML 文档几乎是一对一的关系。 解析算法 HTML不能使用常见的自顶向下或自底向上方法来进行分析。主要原因有以下几点: 语言本身的宽容特性 HTML 本身可能是残缺的，对于常见的残缺，浏览器需要有传统的容错机制来支持它们 解析过程需要反复。对于其他语言来说，源码不会在解析过程中发生变化，但是对于 HTML 来说，动态代码，例如脚本元素中包含的 document.write() 方法会在源码中添加内容，也就是说，解析过程实际上会改变输入的内容 由于不能使用常用的解析技术，浏览器创造了专门用于解析 HTML 的解析器。解析算法在 HTML5 标准规范中有详细介绍，算法主要包含了两个阶段：标记化（tokenization）和树的构建。 解析结束之后 浏览器开始加载网页的外部资源（CSS，图像，Javascript 文件等）。 此时浏览器把文档标记为可交互的（interactive），浏览器开始解析处于推迟（deferred）模式的脚本，也就是那些需要在文档解析完毕之后再执行的脚本。之后文档的状态会变为完成（complete），浏览器会触发加载（load）事件。 注意解析 HTML 网页时永远不会出现无效语法（Invalid Syntax）错误，浏览器会修复所有错误内容，然后继续解析。 CSS 解析 根据 CSS词法和句法 分析CSS文件和 标签包含的内容以及 style 属性的值 每个CSS文件都被解析成一个样式表对象（StyleSheet object），这个对象里包含了带有选择器的CSS规则，和对应CSS语法的对象 CSS解析器可能是自顶向下的，也可能是使用解析器生成器生成的自底向上的解析器 ##页面渲染 通过遍历DOM节点树创建一个Frame 树或渲染树，并计算每个节点的各个CSS样式值 通过累加子节点的宽度，该节点的水平内边距(padding)、边框(border)和外边距(margin)，自底向上的计算Frame 树中每个节点的首选(preferred)宽度 通过自顶向下的给每个节点的子节点分配可行宽度，计算每个节点的实际宽度 通过应用文字折行、累加子节点的高度和此节点的内边距(padding)、边框(border)和外边距(margin)，自底向上的计算每个节点的高度 使用上面的计算结果构建每个节点的坐标 当存在元素使用 floated，位置有 absolutely 或 relatively 属性的时候，会有更多复杂的计算，详见http://dev.w3.org/csswg/css2/ 和 http://www.w3.org/Style/CSS/current-work 创建layer(层)来表示页面中的哪些部分可以成组的被绘制，而不用被重新栅格化处理。每个帧对象都被分配给一个层 页面上的每个层都被分配了纹理(?) 每个层的帧对象都会被遍历，计算机执行绘图命令绘制各个层，此过程可能由CPU执行栅格化处理，或者直接通过D2D/SkiaGL在GPU上绘制 上面所有步骤都可能利用到最近一次页面渲染时计算出来的各个值，这样可以减少不少计算量 计算出各个层的最终位置，一组命令由 Direct3D/OpenGL发出，GPU命令缓冲区清空，命令传至GPU并异步渲染，帧被送到Window Server。 GPU 渲染 在渲染过程中，图形处理层可能使用通用用途的 CPU，也可能使用图形处理器 GPU 当使用 GPU 用于图形渲染时，图形驱动软件会把任务分成多个部分，这样可以充分利用 GPU 强大的并行计算能力，用于在渲染过程中进行大量的浮点计算。 Window Server后期渲染与用户引发的处理渲染结束后，浏览器根据某些时间机制运行JavaScript代码(比如Google Doodle动画)或与用户交互(在搜索栏输入关键字获得搜索建议)。类似Flash和Java的插件也会运行，尽管Google主页里没有。这些脚本可以触发网络请求，也可能改变网页的内容和布局，产生又一轮渲染与绘制。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://lakehumin.github.io/categories/学习笔记/"}],"tags":[{"name":"WEB","slug":"WEB","permalink":"http://lakehumin.github.io/tags/WEB/"}]},{"title":"百度地图离线API制作","slug":"BaiduMapAPI","date":"2016-12-08T07:47:17.000Z","updated":"2017-11-25T08:52:48.479Z","comments":true,"path":"2016/12/08/BaiduMapAPI/","link":"","permalink":"http://lakehumin.github.io/2016/12/08/BaiduMapAPI/","excerpt":"","text":"百度地图离线API制作，以API v1.3为例。更高版本请自行搜索。 第一步访问 http://api.map.baidu.com/api?v=1.3 得到如下内容12345678(function()&#123; window.wise=1; window.netSpeed=254; window.netType=1; window.BMap_loadScriptTime = (new Date).getTime(); document.write('&lt;script type=\"text/javascript\" src=\"http://api.map.baidu.com/getscript?v=1.3&amp;ak=&amp;services=&amp;t=20150527115231\"&gt;&lt;/script&gt;'); document.write('&lt;link rel=\"stylesheet\" type=\"text/css\" href=\"http://api.map.baidu.com/res/13/bmap.css\"/&gt;');&#125;)(); 这一步将获得一个js文件的位置和一个css文件的位置，然后分别下载下来，放在准备好的文件夹里面，我分别存储在/js和/css里面。js的路径后面有若干参数，不管，下载下来的文件重新命名就好，比如js文件命名为apiv1.3.min.js 第二步修改这个js中的代码。由于代码是压缩在一行上的，可通过网上的代码在线格式化。 搜索变量：imgPath，直到找到一段代码 12var x=m?\"https://sapi.map.baidu.com/\":\"http://api.map.baidu.com/\";var cd=&#123;imgPath:x+\"images/\",cityNames:&#123;\"\\u5317\\u4eac\":\"bj\", 把imgPath:x+&quot;images/&quot;中的x去掉即可，这样就变成了跟网络地址无关的相对位置了。这里指出的images文件夹，是与将来的html文件夹平行的目录里面的。 例如： 12var x=m?\"https://sapi.map.baidu.com/\":\"http://api.map.baidu.com/\";var cd=&#123;imgPath:\"images/\",cityNames:&#123;\"\\u5317\\u4eac\":\"bj\", 搜索变量：_baseUrl，直到找到这样的一段代码 1preLoaded:&#123;&#125;,Config:&#123;_baseUrl:x+\"getmodules?v=1.3\",_timeout:5000&#125;, 同样，要去掉x，这个x也是前面这段代码中的x。同时，不仅要去掉x，更要把地址指向js目录。 例如： 1preLoaded:&#123;&#125;,Config:&#123;_baseUrl:\"js/\",_timeout:5000&#125;, 继续搜索下一个_baseUrl，得到下面的代码： 123456window.setTimeout(function()&#123; var cP=cN.Config._baseUrl+\"&amp;mod=\"+cN.Module._arrMdls.join(\",\"); cy.request(cP); cN.Module._arrMdls.length=0; cN.delayFlag=false;&#125;,1); 直接修改cP变量（变量名与版本有关，可能不同），注意：这里把加载地址直接写死 12var cP=cN.Config._baseUrl+\"modules\";cy.request(cP); 这样，我们把动态模块加载改为了手动加载离线模块文件。 访问这个地址 http://api.map.baidu.com/getmodules?v=1.3&amp;mod=map,oppc,tile,control,marker,poly 我们就能拿到相应参数的模块源文件。 新建文件modules，放在js文件夹里面即可。 关键的一步：搜索getTilesUrl直到找到这样的一段（变量名aU可能不一样）123456789101112131415161718aU.getTilesUrl = function(cN, cQ) &#123; var cR = cN.x; var cO = cN.y; var T = \"20150518\"; var cP = \"pl\"; if (this.map.highResolutionEnabled()) &#123; cP = \"ph\" &#125; var cM = j[Math.abs(cR + cO) % j.length] + \"?qt=tile&amp;x=\" + (cR + \"\").replace(/-/gi, \"M\") + \"&amp;y=\" + (cO + \"\").replace(/-/gi, \"M\") + \"&amp;z=\" + cQ + \"&amp;styles=\" + cP + (a9.browser.ie == 6 ? \"&amp;color_dep=32&amp;colors=50\" : \"\") + \"&amp;udt=\" + T; return cM.replace(/-(\\d+)/gi, \"M$1\")&#125;;window.BMAP_NORMAL_MAP = new cv(\"\\u5730\\u56fe\", aU, &#123; tips : \"\\u663e\\u793a\\u666e\\u901a\\u5730\\u56fe\"&#125;); getTilesUrl这个方法，这里就是返回瓦片未知的关键方法。两个参数中，第一个参数是{x，y}，第二个参数就是z，这样xyz就都有了。直接把它计算出来的cM的结果重新计算一下，改成：1cM = \"tiles/\" + cQ + \"/\" + cR + \"/\" + cO + \".jpg\"; .jpg后缀与你下载的瓦片图片格式有关。这样就设置了BMAP_NORMAL_MAP地图类型的地图瓦片获取url，即为放在tiles目录下的瓦片资源。同理可以设置卫星BMAP_SATELLITE_MAP等地图类型的离线瓦片url。 第三步下载相关资源 图片文件像一些logo等图片资源。可通过chrome开发者工具查看缺少的图片文件，以及url。然后自行下载。将图片放在images文件夹中，并修改bmap.css中相应的url为本地路径。 依赖模块API文件 如果缺少某个依赖模块，则无法使用相应的API。 在运行前期工作中的在线地图时，就可发现，依赖的库参数是什么。例如：以下的代码运行，所请求的依赖库参数是http://api.map.baidu.com/getmodules?v=1.3&amp;mod=map,oppc,tile,control 1234567891011&lt;script type=\"text/javascript\"&gt; var map = new BMap.Map(\"container\",&#123;mapType:BMAP_NORMAL_MAP&#125;); var point = new BMap.Point(116.404, 39.915); // 创建点坐标 map.centerAndZoom(point,5); // 初始化地图,设置中心点坐标和地图级别。 //map.addControl(new BMap.MapTypeControl()); map.addControl(new BMap.NavigationControl()); map.enableScrollWheelZoom(); // 启用滚轮放大缩小。 map.enableKeyboard(); // 启用键盘操作。 //map.setCurrentCity(\"北京\"); // 设置地图显示的城市 此项是必须设置的&lt;/script&gt; 总共有哪些依赖模块可以去apiv1.3.min.js中搜索Dependency 瓦片资源可以选择 全能电子地图下载器 下载，其中1.9.5版本有破解，不过有些瓦片无法下载。或者选择自己拼凑瓦片，有教程获取瓦片url。 最后离线API算是做好了，目录结构大致为： css bmap.css images js apiv1.3.min.js modules tiles HawkUI项目中便用到了该离线API，文件在public目录下。","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://lakehumin.github.io/categories/开发工具/"}],"tags":[{"name":"百度地图","slug":"百度地图","permalink":"http://lakehumin.github.io/tags/百度地图/"},{"name":"工具","slug":"工具","permalink":"http://lakehumin.github.io/tags/工具/"}]}]}